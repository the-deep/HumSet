{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878af8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da81e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download these models\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "python -m spacy download en_core_web_sm\n",
    "python -m spacy download es_core_news_sm\n",
    "python -m spacy download fr_core_news_sm\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3174765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import ast\n",
    "import string\n",
    "import spacy\n",
    "import transformers\n",
    "import string\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248285ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\n",
    "    'sectors',\n",
    "    'pillars_1d',\n",
    "    'pillars_2d',\n",
    "    'subpillars_2d',\n",
    "    'subpillars_1d',\n",
    "]\n",
    "\n",
    "ENG_STOP = list(set(stopwords.words('english')))\n",
    "ES_STOP = list(set(stopwords.words('spanish')))\n",
    "FR_STOP = list(set(stopwords.words('french')))\n",
    "\n",
    "stop_words = ENG_STOP + FR_STOP + ES_STOP\n",
    "\n",
    "\n",
    "nlp_models = {\n",
    "    \"en\": spacy.load(\"en_core_web_sm\"),\n",
    "    \"fr\": spacy.load(\"fr_core_news_sm\"),\n",
    "    \"es\": spacy.load(\"es_core_news_sm\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load HumSet Dataset\n",
    "\n",
    "data = pd.read_csv(\"HumSet/humset_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f083ed5",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc775916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop(x, stop_words):\n",
    "    return \" \".join([c for c in word_tokenize(x) if c not in stop_words])\n",
    "\n",
    "def text_preprocess(x, lang):\n",
    "    text = \" \".join([t.lemma_ for t in nlp_models[lang](remove_stop(x, stop_words))\n",
    "          if not t.is_punct and not t.text.isnumeric()])\n",
    "    return text.strip().lower()\n",
    "\n",
    "def pre_process(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    python type list conversion and cleaning\n",
    "    adding a clean_excerpt column with cleaned text on stopwords, nltk, and lemmatitazion\n",
    "    using spacy pre-trained models\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def clean_and_convert(col):\n",
    "        if str(col)==\"nan\":\n",
    "            col = \"[]\"\n",
    "        if col[0]==\"[\" and col[-1]==\"]\":\n",
    "            col = ast.literal_eval(col)\n",
    "        else:\n",
    "            col = [col]\n",
    "        return [a for a in col if a not in [\"None\", \n",
    "                                            \"NOT_MAPPED\", \n",
    "                                            \"UNKNOWN\", None]]\n",
    "    \n",
    "    for c in COLUMNS:\n",
    "        df[c] = df.apply(lambda x: clean_and_convert(x[c]), axis=1)\n",
    "        \n",
    "    df[\"clean_excerpt\"] = df.apply(lambda x: text_preprocess(x[\"excerpt\"], x[\"lang\"]), axis=1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799ed25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_splitting(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Based on: http://scikit.ml/ library\n",
    "    \n",
    "    80%-10%-10% train, validation, test splitting\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    total, classes = [], []\n",
    "    lab = preprocessing.MultiLabelBinarizer()\n",
    "    \n",
    "    for c in COLUMNS:\n",
    "        \n",
    "        fit = lab.fit(df[c])\n",
    "        total.append(fit.transform(df[c]))\n",
    "        classes.append(list(fit.classes_))  \n",
    "        \n",
    "    X_train, y_train, X_test, y_test = iterative_train_test_split(df.index.to_numpy().reshape(-1, 1), \n",
    "                                                                  np.concatenate(total, axis=1), \n",
    "                                                                  test_size=0.1)\n",
    "\n",
    "    X_train, y_train, X_val, y_val = iterative_train_test_split(X_train,\n",
    "                                                                y_train,\n",
    "                                                                test_size=0.1)\n",
    "    \n",
    "    df_train = df[df.index.isin(X_train.reshape(-1))]\n",
    "    df_val = df[df.index.isin(X_val.reshape(-1))]\n",
    "    df_test = df[df.index.isin(X_test.reshape(-1))]\n",
    "    \n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b14716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lead_splitted_recombination(df, df_train, df_val, df_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    proportions are manually fine-tuned\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def recombine_by_lead_id(df1, df2, proportions):\n",
    "        \n",
    "        groups = []\n",
    "        df1_df2_inter = list(set(df1.lead_id).intersection(set(df2.lead_id)))\n",
    "        df1_pivot = df1[~df1.lead_id.isin(df1_df2_inter)]\n",
    "        df2_pivot = df2[~df2.lead_id.isin(df1_df2_inter)]\n",
    "\n",
    "        for i, v in enumerate(df1_df2_inter):\n",
    "            t = df1[df1.lead_id==df1_df2_inter[i]].index.tolist()\n",
    "            v = df2[df2.lead_id==df1_df2_inter[i]].index.tolist()\n",
    "            groups.append(t+v)\n",
    "            \n",
    "        random.shuffle(groups)\n",
    "        index = int((len(groups)*proportions)/100)\n",
    "        one, two = groups[:index], groups[index:]\n",
    "        indexes_1 = [c for e in one for c in e]\n",
    "        indexes_2 = [c for e in two for c in e]\n",
    "\n",
    "        df1= pd.concat([df[df.index.isin(indexes_1)], df1_pivot])\n",
    "        df2= pd.concat([df[df.index.isin(indexes_2)], df2_pivot])\n",
    "    \n",
    "        return df1, df2\n",
    "    \n",
    "    df_train, df_val = recombine_by_lead_id(df_train, df_test, 80)\n",
    "    df_train, df_test = recombine_by_lead_id(df_train, df_test, 85)\n",
    "    df_val, df_test = recombine_by_lead_id(df_val, df_test, 75)\n",
    "    \n",
    "    assert len(set(df_train.lead_id).intersection(set(df_val.lead_id))) == 0\n",
    "    assert len(set(df_train.lead_id).intersection(set(df_test.lead_id))) == 0 \n",
    "    assert len(set(df_val.lead_id).intersection(set(df_test.lead_id))) == 0 \n",
    "    \n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0cec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pre_process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0749fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = iterative_splitting(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_text = lead_splitted_recombination(\n",
    "     data, \n",
    "     df_train, \n",
    "     df_val, \n",
    "     df_test\n",
    " )     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e55bb7",
   "metadata": {},
   "source": [
    "### Random Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbefafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_baseline():\n",
    "    \"\"\"\n",
    "    Example for random baseline as described in the paper.\n",
    "    Saving a csv for each caterogy metrics report.\n",
    "    df_train hardcoded.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(\"./metrics\"):\n",
    "        os.makedirs(\"./metrics\")\n",
    "    \n",
    "    for column in COLUMNS:\n",
    "\n",
    "        mlb = preprocessing.MultiLabelBinarizer()\n",
    "        mlb.fit(df_train[column])\n",
    "\n",
    "        x_test = df_train.excerpt.tolist() # we can select a random column, features are ignored\n",
    "        y_test = mlb.transform(df_train[column])\n",
    "\n",
    "        dummy_clf = DummyClassifier(\n",
    "            strategy=\"stratified\"\n",
    "        )\n",
    "\n",
    "        dummy_clf.fit(x_test, y_test)\n",
    "        y_pred = dummy_clf.predict(x_test)\n",
    "\n",
    "        report = classification_report(y_test, \n",
    "                                       y_pred, \n",
    "                                       target_names=list(mlb.classes_),\n",
    "                                       zero_division=False,\n",
    "                                       output_dict=True)\n",
    "        \n",
    "        results = pd.DataFrame(report).transpose()\n",
    "        results.to_csv(f\"./metrics/random_baseline_{column.upper()}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadd1529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_random_baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4ea6b",
   "metadata": {},
   "source": [
    "### fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d832e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_fasttext_data(df, column, filename=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    we use \"clean_exceprt\" column as our text to encode.\n",
    "    Since fasttext it's vocabulary based model, we want a normalized (in lemma),\n",
    "    and removed stopwords text.\n",
    "    \n",
    "    convert dataframe in fasttext format.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def clean_newline_sentence(x):\n",
    "        x = x.replace(\"\\n\", \" \")\n",
    "        x = x.translate(str.maketrans(' ', ' ', string.punctuation))\n",
    "        return x\n",
    "    \n",
    "    if not os.path.exists(\"./fast_data\"):\n",
    "        os.makedirs(\"./fast_data\")\n",
    "        \n",
    "    total = []\n",
    "    text = [c.strip().lower() for c in df.clean_excerpt]\n",
    "    \n",
    "    target = [[a.strip().lower().replace(\" \", \"*\") for a in c] \n",
    "              if c else [\"NEGATIVE\"] for c in df[column].tolist()]\n",
    "    \n",
    "    for x, y in zip(text, target):\n",
    "        x = clean_newline_sentence(x)\n",
    "        labels = \" \".join([f\"__label__{c}\" for c in y])\n",
    "        total.append(\" \".join([labels, x]))\n",
    "        \n",
    "    a =  \"\\n\".join(total)\n",
    "    with open(f\"./fast_data/{filename}\", \"w+\") as f:\n",
    "        f.write(a)\n",
    "        \n",
    "        \n",
    "def get_pred(filename, model, thres = 0.5):\n",
    "    \n",
    "    \"\"\"\n",
    "    function used to get predictions using resulted fasttext model\n",
    "    \"\"\"\n",
    "    \n",
    "    tot = []\n",
    "    test = open(filename, \"r\").read().split(\"\\n\")\n",
    "    text = [\" \".join([c for c in t.split() if \"__label__\" not in c]) for t in test]\n",
    "\n",
    "    for s in test:\n",
    "        labels = [c for c in s.split() if \"__label__\" in c]\n",
    "        ss = \" \".join([c for c in s.split() if \"__label__\" not in c]).strip()\n",
    "        pred = model.predict(ss, k=-1, threshold=thres)\n",
    "        lab = [c.replace(\"__label__\",\"\").replace(\"*\", \" \") for c in pred[0] if not \"NEGATIVE\" in c]\n",
    "        tot.append(lab)\n",
    "        \n",
    "    return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dbe3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fasttext(return_model=False):\n",
    "    \n",
    "    if not os.path.exists(\"./metrics\"):\n",
    "        os.makedirs(\"./metrics\")\n",
    "    \n",
    "    models = {}\n",
    "    for column in COLUMNS:\n",
    "        \n",
    "        prepare_fasttext_data(df_train, column, \"fasttextdata.train\")\n",
    "        prepare_fasttext_data(df_val, column, \"fasttextdata.val\")\n",
    "        prepare_fasttext_data(df_test, column, \"fasttextdata.test\")\n",
    "\n",
    "        model = fasttext.train_supervised(\n",
    "              input=\"./fast_data/fasttextdata.train\",\n",
    "              autotuneValidationFile=\"./fast_data/fasttextdata.val\", # automatic hyperparameters tuning provided in fasttext \n",
    "              thread=5,\n",
    "              loss=\"ova\" # one-vs-all loss for multi-label output\n",
    "          )\n",
    "        \n",
    "        if return_model:\n",
    "            models.update({column: model})\n",
    "\n",
    "        predictions = get_pred(\"./fast_data/fasttextdata.test\", model)\n",
    "\n",
    "        mlb = preprocessing.MultiLabelBinarizer()\n",
    "        mlb.fit(predictions)\n",
    "        y_pred = mlb.transform(predictions)\n",
    "        y_test = mlb.transform([[c.lower() for c in a] for a in df_test[column]])\n",
    "\n",
    "        report = classification_report(y_test, \n",
    "                                       y_pred, \n",
    "                                       target_names=list(mlb.classes_),\n",
    "                                       zero_division=False,\n",
    "                                       output_dict=True)\n",
    "\n",
    "        results = pd.DataFrame(report).transpose()\n",
    "        results.to_csv(f\"./metrics/fasttext_{column.upper()}.csv\")\n",
    "    \n",
    "    if return_model: return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d779a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fasttext()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ce6680",
   "metadata": {},
   "source": [
    "### Pre-trained Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7553c6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e227b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a GPU is needed here\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6588bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here selection which pre-trained language model to fine-tuned\n",
    "XTREME_DISTL = \"microsoft/xtremedistil-l6-h256-uncased\"\n",
    "XML_ROBERT = \"xlm-roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0426872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer(backbone:str = XTREME_DISTL):\n",
    "    \n",
    "    # parameters\n",
    "    epochs = 3\n",
    "    max_length = 100\n",
    "    batch_size = 32\n",
    "    learning_rate = lr=2e-5\n",
    " \n",
    "    \n",
    "    for column in COLUMNS:\n",
    "        \n",
    "        mlb = preprocessing.MultiLabelBinarizer()\n",
    "        mlb.fit(df_train[column])\n",
    "        num_labels = len(list(mlb.classes_))\n",
    "        \n",
    "        Y_train = pd.DataFrame(mlb.transform(df_train[column]), \n",
    "                               columns=list(mlb.classes_))\n",
    "        Y_val = pd.DataFrame(mlb.transform(df_val[column]), \n",
    "                             columns=list(mlb.classes_))\n",
    "        Y_test = pd.DataFrame(mlb.transform(df_test[column]), \n",
    "                              columns=list(mlb.classes_))\n",
    "        \n",
    "        tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "            backbone, \n",
    "            do_lower_case=True, \n",
    "            create_token_type_ids_from_sequences=True\n",
    "        )\n",
    "\n",
    "        model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "            XTREME_DISTL,\n",
    "            num_labels=num_labels\n",
    "        )\n",
    "        model.cuda()\n",
    "        \n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'gamma', 'beta']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.0}\n",
    "        ]\n",
    "\n",
    "        optimizer = transformers.AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=learning_rate,\n",
    "            correct_bias=True\n",
    "        )\n",
    "\n",
    "        \n",
    "        encodings = tokenizer.batch_encode_plus(train_data.excerpt.tolist(), \n",
    "                                                max_length=max_length,\n",
    "                                                pad_to_max_length=True, \n",
    "                                                truncation=True)\n",
    "        \n",
    "        encodings_val = tokenizer.batch_encode_plus(val_data.excerpt.tolist(), \n",
    "                                                    max_length=max_length, \n",
    "                                                    pad_to_max_length=True, \n",
    "                                                    truncation=True)\n",
    "        input_ids = encodings['input_ids']\n",
    "        attention_masks = encodings['attention_mask']\n",
    "        input_ids_test = encodings_val['input_ids']\n",
    "        attention_masks_test = encodings_val['attention_mask']\n",
    "        \n",
    "        train_inputs = torch.tensor(input_ids)\n",
    "        train_labels = torch.tensor(Y_train.to_numpy())\n",
    "        train_masks = torch.tensor(attention_masks)\n",
    "\n",
    "        validation_inputs = torch.tensor(input_ids_test)\n",
    "        validation_labels = torch.tensor(Y_val.to_numpy())\n",
    "        validation_masks = torch.tensor(attention_masks_test)\n",
    "        \n",
    "        \n",
    "        train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "        train_sampler = RandomSampler(train_data)\n",
    "        train_dataloader = DataLoader(train_data, \n",
    "                                      sampler=train_sampler, \n",
    "                                      batch_size=batch_size)\n",
    "\n",
    "        validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "        validation_sampler = SequentialSampler(validation_data)\n",
    "        validation_dataloader = DataLoader(validation_data, \n",
    "                                           sampler=validation_sampler, \n",
    "                                           batch_size=batch_size)\n",
    "        \n",
    "        \n",
    "        train_loss_set = []\n",
    "        for _ in trange(epochs, desc=\"Epoch\"):\n",
    "\n",
    "            model.train()\n",
    "            \n",
    "            tr_loss = 0 \n",
    "            nb_tr_examples, nb_tr_steps = 0, 0\n",
    "            \n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                b_input_ids, b_input_mask, b_labels  = batch\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "                \n",
    "                logits = outputs[0]\n",
    "                loss = BCEWithLogitsLoss(\n",
    "                    logits.view(-1,num_labels),\n",
    "                    b_labels.type_as(logits).view(-1,num_labels)\n",
    "                )\n",
    "                \n",
    "                train_loss_set.append(loss.item())    \n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_examples += b_input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "\n",
    "            print(\"loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "            model.eval()\n",
    "            \n",
    "            logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "            \n",
    "            for i, batch in enumerate(validation_dataloader):\n",
    "                \n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                b_input_ids, b_input_mask, b_labels = batch\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    \n",
    "                    outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "                    b_logit_pred = outs[0]\n",
    "                    pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "                    b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "                    pred_label = pred_label.to('cpu').numpy()\n",
    "                    b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "                tokenized_texts.append(b_input_ids)\n",
    "                logit_preds.append(b_logit_pred)\n",
    "                true_labels.append(b_labels)\n",
    "                pred_labels.append(pred_label)\n",
    "\n",
    "            pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "            true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "            threshold = 0.50\n",
    "            pred_bools = [pl>threshold for pl in pred_labels]\n",
    "            true_bools = [tl==1 for tl in true_labels]\n",
    "            val_f1 = f1_score(true_bools,pred_bools,average='macro')\n",
    "\n",
    "            print('Macro-Average F1-score: ', val_f1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        test_encodings = tokenizer.batch_encode_plus(df_text.excerpt.tolist(),\n",
    "                                                     max_length=max_length,\n",
    "                                                     pad_to_max_length=True)\n",
    "        \n",
    "        test_input_ids = test_encodings['input_ids']\n",
    "        test_attention_masks = test_encodings['attention_mask']\n",
    "        \n",
    "        test_inputs = torch.tensor(test_input_ids)\n",
    "        test_labels = torch.tensor(Y_test.to_numpy())\n",
    "        test_masks = torch.tensor(test_attention_masks)\n",
    "\n",
    "        test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "        test_sampler = SequentialSampler(test_data)\n",
    "        test_dataloader = DataLoader(test_data, \n",
    "                                     sampler=test_sampler, \n",
    "                                     batch_size=batch_size)\n",
    "\n",
    "        logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "        for i, batch in enumerate(test_dataloader):\n",
    "            \n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                \n",
    "                outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "                \n",
    "                b_logit_pred = outs[0]\n",
    "                pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "                b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "                pred_label = pred_label.to('cpu').numpy()\n",
    "                b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "            tokenized_texts.append(b_input_ids)\n",
    "            logit_preds.append(b_logit_pred)\n",
    "            true_labels.append(b_labels)\n",
    "            pred_labels.append(pred_label)\n",
    "\n",
    "        tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n",
    "        pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "        true_labels = [item for sublist in true_labels for item in sublist]\n",
    "        \n",
    "        y_test = [tl==1 for tl in true_labels]\n",
    "        y_pred = [pl>0.50 for pl in pred_labels]\n",
    "        \n",
    "        report = classification_report(y_test, \n",
    "                                       y_pred, \n",
    "                                       target_names=list(mlb.classes_),\n",
    "                                       zero_division=False,\n",
    "                                       output_dict=True)\n",
    "\n",
    "        results = pd.DataFrame(report).transpose()\n",
    "        results.to_csv(f\"./metrics/{backbone}_{column.upper()}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb179a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web",
   "language": "python",
   "name": "web"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
